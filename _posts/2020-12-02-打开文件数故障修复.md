---
title: 打开文件数故障修复
date: 2020-12-02 00:00:00 +0800
categories: [大数据]
tags: [故障修复]
---

# 【故障修复】打开文件数故障修复

---
## 背景
在重启计算/存储节点主机后，有时注意到datanode的进程limit会被限制。其最大打开文件数max open file会被限制成4096。这里简单介绍下具体原因和修复方法。


## 原因
集群节点重启后，会先启动Ambari-agent，目前会因为某些不明原因，由root启动的Ambari-agent的打开文件数被限制成1024:4096（soft/hard）。随后Amabri-agent会以hdfs用户的来启动datanode，此时，datanode作为ambari-agent的子进程，其打开文件数会受父进程的限制，被限制为4096:4096。


## 修复方法
首先检查`/etc/security/limit.conf`，以及`/etc/security/limit.d/`路径下的配置文件中，limit的设定是否正确。
若配置正确，则开始检查Ambari-agent的打开文件数限制，以及datanode的文件数限制，注意datanode的主副进程（主hdfs，副root）。
```
grep 'open files' /proc/$(ps aux | grep "[A]mbariAgent" |  awk '{print $2}')/limits
ps aux | grep datanode
cat /proc/{datanodepid}/limits
```
![图片描述](/assets/media/故障修复打开文件数故障修复/tapd_48728548_1597290830_59.png)

一般情况下，能够发现Max open files数值与正常不符，目前集群内root下进程limit应当为100001。
使用命令重启Ambari-agent
```
ambari-agent stop
ambari-agent start
```
观察limit变化，一般会恢复正常值。
![图片描述](/assets/media/故障修复打开文件数故障修复/tapd_48728548_1597291042_27.png)

在Ambari上重启datanode进程。即可恢复。
验证恢复后的limit是否正常。

## 注意
切不可直接使用`prlimit --nofile=100001:100001 --pid {datanodepid}`的命令来修改。
在ambari重启datanode后同样会回到4096。这个比较隐性，不好发现。
目前limit相关的问题加入了日报，要注意查看。

## 补充下真正的原因和永久的修复方法
max openfile问题来源于/etc/init.d里面的ambari启动脚本
使用systemd维护时，会忽略root的userlimit直接用默认值。
原来配置的override方式都不生效，只能在重启后再次重启amabri-agent和组件修复ulimit问题。

对于 linux 的 limit，可以了解下https://blog.51cto.com/kaifly/2392020

最后的解决方案，所有的 datanode都在/etc/systemd/system.conf内添加DefaultLimitNOFILE=100001参数
关键是，需要重启整机参数才生效，systemd reload daemon没用。不过这里是也是针对主机故障重启之后，ambari 拉起组件的场景，所以配置上即可。