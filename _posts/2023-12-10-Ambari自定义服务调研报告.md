---
title: Ambari自定义服务调研报告
date: 2023-12-10 19:10 +0800
categories: [大数据, ambari]
tags: [ambari]
---

# Terminology名词解释

## Service服务

服务在Ambari中代表着Hadoop生态圈中的各个服务（也可以有自己适配的服务），比如HDFS，Hbase，Hive，Yarn之类。一个服务可能有多个组件（Components，比如Yarn的Resource Manager，Node Manager等），也可能只有客户端库（比如Pig就没有服务端守护进程之类的）。

## Component组件

一个服务对应一个或多个组件，比如HDFS有NN，DN，ZKFC，QJN等等。组件可以是可选的，一个组件可以部署在多个节点上（比如DN）。

## Node/Host节点

节点代表着集群的机器。两个英文代表的意义类似。

## Node-Component节点组件

节点组件特指着节点上的某个组件实例。比如某个节点上的特定Datanode实例是一个节点组件。

## Operation操作

操作指的是一系列在集群中实施的变更或动作，通常是响应用户请求，或者达到某种变更结果实施的。比如，启动一个服务，执行一次测试都算操作。一个操作可能包含多个先后排列的复杂的动作，比如加入新服务后会进行测试验证操作等。

## Task任务

任务是发送到节点执行的动作单元。举个例子，一个动作可能会到n1节点上安装namenode，zkfc，会到n2节点上安装datanode，这时，n1的任务就是安装nn，zkfc，而n2的任务就是安装datande。

## Stage阶段

阶段指的是一系列为了完成操作而组合成的任务。阶段之间互相独立，相同阶段的各任务可以在不同节点间并行实施。

## Action动作

动作指的是发到某个或某组节点上执行的任务，每个动作都有一个id，节点返回的反馈信息是以动作为粒度的。一个动作可以被视为执行中的阶段。在Ambari中，请求，阶段，动作是一一对应的。

## Stage Plan阶段计划

一个操作通常包含了在不同节点上执行的一系列任务，这些任务也往往有着前后顺序依赖。所以这些任务可以分配到不同的阶段中去，以阶段间的排序控制依赖。单个阶段中的所有任务都可以在不同节点中并发执行。

## Manifest清单

清单指的是发送到节点执行的一系列任务。清单必须能够定义任务，且能够序列化。清单也需要能留存在磁盘中方便记录或恢复。

## Role角色

这个还没懂，看下后续用法。文档是说可以关联一个组件或一个动作。

## Stacks服务栈

服务栈是我这边自己的翻译，这是一个服务的集合，比如HDP就是属于一个Stack，涵盖多个版本。服务栈可以有版本的继承关系。

# Ambari-server的文件结构

## Server路径

我们使用的2.7.1版本的Amabri，在Centos安装后，默认将服务相关文件放置在/var/lib/ambari-server/下。这里需要关注的是resource路径，下面包含了Ambari在各个数据库中可用的DDL建表语句，各类jar包，ambari本身以及hosts相关的操作脚本等等。

### Stack路径

在Resource路径下，最关键的就是Stack的路径了，里面包含了一系列服务以及服务说使用的配置信息，元信息，还有操作脚本。Stack的整体文件结构如下：

```
|_ stacks
   |_ <stack_name>
      |_ <stack_version>
         metainfo.xml
         |_ hooks
         |_ repos
            repoinfo.xml
         |_ properties
            |_ stack_features.json
            |_ stack_packages.json
            |_ stack_tools.json
         |_ services
            |_ <service_name>
               metainfo.xml
               metrics.json
               |_ configuration
                  {configuration files}
               |_ package
                  {files, scripts, templates}
```

就像之前介绍的，Stack其实包含了多个版本，版本号作为路径存在，版本路径下metainfo.xml是stack的源信息，包含了该版本是否激活，以及所需JDK的版本信息。（在3.1版本HDP中，大部分组件使用了stack的继承能力，因此服务的实际操作脚本及大部分配置文件都在3.0版本路径下）repos路径包含了stack的默认yum源信息，在Ambari安装的时候，可以配置自定义的源，生产环境下，最好配置私有源，现在HDP已经不开放给免费用户了，源也关闭了，使用私有源能够有效防范这种问题。

## Properties路径

这个路径包哈了Stack服务栈相关的各类功能，基础服务配置项等，stack_packages还包含了各服务的组件名，配置路径等信息。

## Service路径

这里就是所有服务相关配置文件存放的位置了。这里以最简单的服务Tez为例子做下服务路径下文件功能的介绍吧。

```
TEZ
├── configuration
│   ├── tez-env.xml
│   └── tez-site.xml
├── kerberos.json
├── metainfo.xml
├── package
│   ├── archive.zip
│   └── scripts
│       ├── params_linux.py
│       ├── params.py
│       ├── params_windows.py
│       ├── pre_upgrade.py
│       ├── service_check.py
│       ├── tez_client.py
│       ├── tez.py
├── service_advisor.py
└── themes
    └── directories.json
```

可以看到，服务下包含几个路径，configuration，package，themes

configuration 以xml格式定义的配置文件

package/scripts 服务操作的脚本，定义了各类操作比如服务的起停，安装，状态检查流程等

themes 以json格式定义ambari的配置页展示的栏目

除此之外，还有其他可能不在TEZ目录的文件及功能可以关注

metainfo.xml 服务的元信息参数，定义服务的组件，定义这些组件应该有的数量，定义组件类型，定义可以对组件进行的操作等。可以说这个文件是关联service本身以及package，theme，configuration的关键文件。

kerberos.json 定义kerberos相关配置

service_advisor.py 根据配置好的建议参数，触发各类自动配置流程，或者在配置发布前进行review和推荐操作。

alert.json 定义告警相关内容，可以监控端口状态，返回状态，也可以转接定义到python脚本来完成告警能力。

# Ambari的自定义服务开发

学习Ambari的自定义服务开发，最好的就是在别人的基础上做修改了，可以通过修改并实现一个项目来了解各个板块的实现方式。个人比较推荐prestodb的[ambari-presto-service项目](https://github.com/prestodb/ambari-presto-service)，这个项目实现了在ambari里安装，变更，调试presto集群的操作。但是，现有prestodb的版本相比ambari-presto-service的版本已经超出不少了，且config中，尤其是针对connector的配置仍有优化空间，可以结合需求做一些升级，比如说实现多集群配置，服务自启动，自动状态探测告警之类。

## Mpack安装方式 vs Stack安装方式

Amabri默认提供的安装方式是mpack的方式，但是现有的mpack打包的文档不是很全，而自定义组件，可以直接采用将service包放入对应的stack中的方式安装。比如ambari-presto-service的安装，只需在Amabri的stack目录“/var/lib/ambari-server/resources/stacks/HDP/3.0/services”下，创建PRESTO文件夹，并将service相关的文件及路径放置其中，最后重启ambari-server即可。重启后，在ambari的stack and versions的配置界面中，就可以发现Presto了。但是，这个service放入ambari后，并不能进行后续的安装流程，因为现有的版本并不适配，且service需要做一些调整来适应我们测试环境的需求。

## Meta文件

meta文件中包含了stack and version中对presto组件的介绍，对应版本，以及组件信息。我们需要安装最新的presto版本0.266版，需要在这里修改下。meta文件中也包含了各组件的定义，以及组件对应的操作脚本映射，这里，coordinator对应了package/scripts路径下的presto_coordinator.py脚本，脚本超时时间配置为20分钟。各组件同时有category（主从）以及cardinality（节点数量）配置，ambari会按照要求的数量限制可安装的节点数。configuration-dependencies则定义了service所包含的配置xml文件，这些文件默认放在configuration下，对于presto，有config.properties（presto常规参数配置），node.properties（节点参数配置），jvm.config（节点jvm参数配置），connector.properties（连接数据库的连接器参数配置）。meta文件最后定义了presto服务的控制台视图模版，默认是位于themes路径下的theme.json文件。

一个完整的meta.xml的配置示例如下：

```xml
<metainfo>
	<schemaVersion>2.0</schemaVersion> # meta配置文件的版本
	  <services> # 服务标签，下面包含服务的配置
	    <service>
	      <name>PRESTO</name> # 服务名
	      <displayName>Presto</displayName># 服务在ambari中展示的名称
	      <comment>Presto is an open source distributed SQL query engine for running
	        interactive analytic queries against data sources of all sizes ranging
	        from gigabytes to petabytes.
	      </comment> # 服务在ambari配置界面中的简介
	      <version>0.266</version> # 服务版本
	      <components>
	        <component> # 组件标签，下面包含组件的配置
	          <name>PRESTO_COORDINATOR</name> # 组件名
	          <displayName>Presto coordinator</displayName> # 组件在ambari中展示的名称
	          <category>MASTER</category> # 属于master还是slave
	          <cardinality>1+</cardinality> # 定义数量
	          <versionAdvertised>true</versionAdvertised> # 升级的时候的配置，组件是否通告版本
	          <commandScript>
	            <script>scripts/presto_coordinator.py</script> # 脚本路径/脚本名
	            <scriptType>PYTHON</scriptType> # 脚本类型，支持PYTHON，SHELL
	            <timeout>1200</timeout> # 超时时间
	          </commandScript>
	        </component>

			<configuration-dependencies> # 配置标签，下面是配置文件的元信息
        <config-type>node.properties</config-type> # 配置文件名
      </configuration-dependencies>

      <themes> # 模版标签，下面是ambari页面模版的配置
        <theme>
          <fileName>theme.json</fileName> # 模版名
          <default>true</default> # 是否是默认项
        </theme>
      </themes>

    </service>
  </services>
</metainfo>
```

## Theme文件

位于themes路径下的theme.json文件，定义了presto的控制台界面。在layouts一栏中，我们可以看到settings tab配置栏的定义，在配置栏中可以配置node config，general config，connector config或者jvm config。下面的placement中则定义了各section对应的配置文件及配置项，其实，在下面的xml文件中也会定义各参数是否在配置界面中显示。没有theme.json的话，会直接套用xml文件中的参数用作configuration。

简单的theme.json配置如下：

```json
{
  "name": "default", #配置名
  "description": "Default theme for Presto service", #配置介绍
  "configuration": {
    "layouts": [
      {
        "name": "default", #layout名
        "tabs": [
          {
            "name": "settings", #tab名
            "display-name": "Settings", #tab的展示名
            "layout": {
              "tab-columns": "2", #tab的列数
              "tab-rows": "3", #tab的行数
              "sections": [ #模块配置
                {
                  "name": "section-node-config", #模块名
                  "display-name": "Node Config", #模块展示名
                  "row-index": "0", #在tab中的位置信息
                  "column-index": "0",
                  "row-span": "1",
                  "column-span": "1",
                  "subsections": [ #有哪些配置项
                    {
                      "name": "subsection-node-config",
                      "row-index": "0",
                      "column-index": "0",
                      "row-span": "1",
                      "column-span": "1"
                    }
                  ]
                }
              ]
            }
          }
        ]
      }
    ],
    "placement": { #这里是对应模块的配置项，和上面的配置呼应，和配置文件里的配置项关联
      "configuration-layout": "default",
      "configs": [
        {
          "config": "node.properties/node.environment",
          "subsection-name": "subsection-node-config"
        }
      ]
    },
    "widgets": [ #这里是定义各个模块的类型，是文本，还是路径，还是可滑动的交互栏等等
      {
        "config": "node.properties/node.environment",
        "widget": {
          "type": "text-area"
        }
      }
    ]
  }
}
```

## Configuration文件

configuration路径下包含了presto的基础配置文件，这些配置文件里的参数也可能会在meta及theme中引用，而最终的定义一定在configuration文件中。每个配置项都有特定的控制参数，这些参数可以控制参数的大小，是否可以override，是否在amabri配置页面中显示等等。这里贴一个Configuration范例和一些控制参数的说明。

```xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>node-scheduler.include-coordinator</name> # 配置名
    <value>false</value> # 默认值
    <description> # 配置介绍，鼠标悬浮在ambari配置界面上会显示出来
      Allow scheduling work on the coordinator. For larger clusters, processing
      work on the coordinator can impact query performance because the machine’s
      resources are not available for the critical task of scheduling, managing
      and monitoring query execution.
    </description>
    <value-attributes> # 配置的控制项
      <type>value-list</type> # 配置类型，这里是列表型的，只能从这两个值里选
      <entries>
        <entry>
          <value>true</value>
          <label>Enabled</label>
        </entry>
        <entry>
          <value>false</value>
          <label>Disabled</label>
        </entry>
      </entries>
      <selection-cardinality>1</selection-cardinality> # 只能选一个
    </value-attributes>
  </property>

  <property>
    <name>query.max-memory</name>
    <value>50GB</value>
    <description>
      The maximum amount of distributed memory that a query may use.

      If you'd like to enter a value higher than the maximum on the slider,
      click on the pencil that appears when you hover over the setting and
      ignore that higher values are not recommended.
    </description>
    <value-attributes>
      <type>int</type> # int型的配置，可以选择最大最小值控制
      <minimum>0</minimum>
      <maximum>300</maximum>
      <increment-step>2</increment-step> # 这里可以控制滑块的step
      <unit>GB</unit>
    </value-attributes>
  </property>

#这里贴一个从kerberos配置文件中截的配置，这个配置项在初始化后，在后续的配置视图中看不到
	<property>
	    <name>ldap_url</name>
	    <display-name>LDAP url</display-name>
	    <description>
	      The URL to the Active Directory LDAP Interface
	      Example: ldaps://ad.example.com:636
	    </description>
	    <value/>
	    <value-attributes>
	      <visible>false</visible> # 配置不可见，可以酌情调整
	      <overridable>false</overridable> # 节点级别配置不可override
	      <type>ldap_url</type> # 配置类型就是ldap_url
	    </value-attributes>
	    <on-ambari-upgrade add="true"/> # 在升级ambari后是否可以重新配置？
	  </property>

</configuration>
```

## Scrpits文件

在Amabri的stack中，每个 Service 都会有 start、stop、status、configure 这样的命令，可以称之为生命周期的控制命令（lifecycle command）。Service 的每个组件（Component）都必须实现这几个命令的逻辑。为了让用户可以更好地控制每个 Service 以及每个component，Ambari 支持了自定义命令（Custom Command）。不过目前只能支持到组件级别（Component Level），Service Level 的还不支持。在Meta中，我们已经为各服务组件定义好了操作对应的执行脚本，比如，针对coordinator，就指向了scripts/presto_coordinator.py，这里我们简略提一下各脚本的引用库，以及实现方法吧。

presto_coordinator.py

```python
# -*- coding: utf-8 -*-
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import uuid
import os.path as path

# resource_management库是自定义命令的基础库之一，位置一般在/usr/lib/ambari-server/lib/resource_management，
# 感兴趣的话可以了解下

from resource_management.libraries.script.script import Script
# 引入Script类
"""
  Executes a command for custom service. stdout and stderr are written to
  tmpoutfile and to tmperrfile respectively.
  Script instances share configuration as a class parameter and therefore
  different Script instances can not be used from different threads at
  the same time within a single python process

  Accepted command line arguments mapping:
  1 command type (START/STOP/...)
  2 path to command json file
  3 path to service metadata dir (Directory "package" inside service directory)
  4 path to file with structured command output (file will be created)
  """

from resource_management.core.resources.system import Execute
# 引入Execute方法用于执行shell命令

from resource_management.core.exceptions import ExecutionFailed, ComponentIsNotRunning
# 引入exception用于规范化的exception handling

from common import PRESTO_RPM_URL, PRESTO_RPM_NAME, create_connectors, \
    delete_connectors
from presto_client import smoketest_presto, PrestoClient
# 这些是本地的脚本，用于定义一部分参数配置，还有测试（smoketest）

class Coordinator(Script):
    def install(self, env):
        from params import java_home
				# 这里安装coodinator是通过rpm包安装的，通过wget获取rpm包，我们配置好rpm的获取位置就好，可以放到httpd里
        Execute('wget --no-check-certificate {0}  -O /tmp/{1}'.format(PRESTO_RPM_URL, PRESTO_RPM_NAME))
        Execute('export JAVA8_HOME={0} && rpm -i /tmp/{1}'.format(java_home, PRESTO_RPM_NAME))
        self.configure(env)

    def stop(self, env):
        from params import daemon_control_script
        # 这里执行“daemon_control_script”是指代的presto包安装后的/etc/init.d/presto控制脚本，里面对应了presto的起停
        # 这个脚本因为是sudo调用，会报错，可以使用sed去掉sudo语句，presto一般用root起也没什么问题
        Execute('{0} stop'.format(daemon_control_script))

    def start(self, env):
        from params import daemon_control_script, config_properties, \
            host_info
        self.configure(env)
        Execute('{0} start'.format(daemon_control_script))
        if 'presto_worker_hosts' in host_info.keys():
            all_hosts = host_info['presto_worker_hosts'] + \
                        host_info['presto_coordinator_hosts']
        else:
            all_hosts = host_info['presto_coordinator_hosts']
				# 这里实现了client中的测试，获取所有hosts目录，确保每个coodinator和worker节点都起来了，并测试默认tpch库内的查询是否正常
        smoketest_presto(PrestoClient('localhost', 'root', config_properties['http-server.http.port']), all_hosts)

    def status(self, env):
				# 用来检测服务状态
        from params import daemon_control_script
        try:
            Execute('{0} status'.format(daemon_control_script))
        except ExecutionFailed as ef:
            if ef.code == 3:
                raise ComponentIsNotRunning("ComponentIsNotRunning")
            else:
                raise ef

    def configure(self, env):
        # 实现参数配置
        from params import node_properties, jvm_config, config_properties, \
            config_directory, memory_configs, host_info, connectors_to_add, connectors_to_delete
        key_val_template = '{0}={1}\n'

        with open(path.join(config_directory, 'node.properties'), 'w') as f:
            for key, value in node_properties.iteritems():
                f.write(key_val_template.format(key, value))
            f.write(key_val_template.format('node.id', str(uuid.uuid4())))
            # 这里是为每个node生成了一个独特的uuid
            f.write(key_val_template.format('node.data-dir', '/var/lib/presto'))

        with open(path.join(config_directory, 'jvm.config'), 'w') as f:
            f.write(jvm_config['jvm.config'])

        with open(path.join(config_directory, 'config.properties'), 'w') as f:
            for key, value in config_properties.iteritems():
                if key == 'query.queue-config-file' and value.strip() == '':
                    continue
                if key in memory_configs:
                    value += 'GB'
                f.write(key_val_template.format(key, value))
            f.write(key_val_template.format('coordinator', 'true'))
            f.write(key_val_template.format('discovery-server.enabled', 'true'))

        create_connectors(node_properties, connectors_to_add)
        delete_connectors(node_properties, connectors_to_delete)
        # This is a separate call because we always want the tpch connector to
        # be available because it is used to smoketest the installation.
        create_connectors(node_properties, "{'tpch': ['connector.name=tpch']}")

if __name__ == '__main__':
    Coordinator().execute()
```

params.py

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from resource_management.libraries.script.script import Script

# config object that holds the configurations declared in the config xml file
# 这里用于获取配置文件里定义的各项配置
config = Script.get_config()

node_properties = config['configurations']['node.properties']
jvm_config = config['configurations']['jvm.config']
config_properties = config['configurations']['config.properties']

connectors_to_add = config['configurations']['connectors.properties']['connectors.to.add']
connectors_to_delete = config['configurations']['connectors.properties']['connectors.to.delete']

daemon_control_script = '/etc/init.d/presto'
config_directory = '/etc/presto'

memory_configs = ['query.max-memory-per-node', 'query.max-memory']

# 这里其实提取的是更上层的配置项了
host_info = config['clusterHostInfo']

host_level_params = config['hostLevelParams']
# 这里脚本有bug，做了变更，指向了正确的配置参数项，这里实现了
# java_home环境同ambari的默认java环境适配，这里要求amabri的java版本（也就是所有组件使用的java版本）
# 必须高于jdk1.8_191版，目前集群用的版本还是比较低的，可以通过配置文件自定义java_home的方式
# 实现分离配置，但是需要改造下启动，停止presto的脚本
ambari_level_params = config['ambariLevelParams']
java_home = ambari_level_params['java_home']
```

common.py

```python
# -*- coding: utf-8 -*-
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import ast
import ConfigParser

from resource_management.core.resources.system import Execute

script_dir = os.path.dirname(os.path.realpath(__file__))
# 这里利用config parser直接定义了一个download的配置文件
# download.ini
# [download]
# presto_rpm_url = http://10.1.80.89/presto/presto-server-rpm-0.266.rpm
# presto_cli_url = http://10.1.80.89/presto/presto-cli-0.266-executable.jar
config = ConfigParser.ConfigParser()
config.readfp(open(os.path.join(script_dir, 'download.ini')))

# 取出 PRESTO_RPM_URL，PRESTO_RPM_NAME， PRESTO_CLI_URL等参数配置
PRESTO_RPM_URL = config.get('download', 'presto_rpm_url')
PRESTO_RPM_NAME = PRESTO_RPM_URL.split('/')[-1]
PRESTO_CLI_URL = config.get('download', 'presto_cli_url')

# 这里是hack了一个配置connector的方法，presto中connector需要配置在单独的文件里，这里通过
# 解析dictionary配置来实现connector的添加或者删除
# dictionary范例：
# {
#        'hive': ['connector.name=hive-cdh4', 'hive.metastore.uri=thrift://example.net:9083'],
#        'kafka': ['connector.name=kafka', 'kafka.table-names=table1,table2', 'kafka.nodes=host1:port,host2:port']
# }
def create_connectors(node_properties, connectors_to_add):
    if not connectors_to_add:
        return
    Execute('mkdir -p {0}'.format(node_properties['plugin.config-dir']))
    connectors_dict = ast.literal_eval(connectors_to_add)
    for connector in connectors_dict:
        connector_file = os.path.join(node_properties['plugin.config-dir'], connector + '.properties')
        with open(connector_file, 'w') as f:
            for lineitem in connectors_dict[connector]:
                f.write('{0}\n'.format(lineitem))

def delete_connectors(node_properties, connectors_to_delete):
    if not connectors_to_delete:
        return
    connectors_list = ast.literal_eval(connectors_to_delete)
    for connector in connectors_list:
        connector_file_name = os.path.join(node_properties['plugin.config-dir'], connector + '.properties')
        Execute('rm -f {0}'.format(connector_file_name))
```

# 总结

Ambari本身是一个复杂而强大的运维管理平台，虽然主要面向Hadoop生态服务的部署和管理做了适配，但它仍然是一个自定义程度极高的平台。我们可以依托它的配置同步，操作下发逻辑，实现自定义组件的安装，配置，操作，监控等运维能力。我们可以开发Presto，Clickhouse或其他第三方服务对应的Ambari Custom Service，提升大数据运维整体的自动化运维能力。