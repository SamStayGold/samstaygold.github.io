---
title: Tez原理及优化建议
date: 2020-09-17 00:00:00 +0800
categories: [大数据]
tags: [tez]
---

# tez原理及优化建议

### 1. tez控制map数
tez中的map数和哪些参数相关？
- tez.grouping.max-size(default 1073741824 which is 1GB)
- tez.grouping.min-size(default 52428800 which is 50MB)
- tez.grouping.split-count(not set by default)

### 2. tez如何控制reduce数
- hive.exec.reducers.bytes.per.reducer(default 256000000)
- hive.exec.reducers.max(default 1009)
- hive.tez.auto.reducer.parallelism(default false)


### 3. Tez和传统mr的对比
- MR性能差，资源消耗大，如：Hive作业之间的数据不是直接流动的，而是借助HDFS作为共享数据存储系统，即一个作业将处理好的数据写入HDFS，下一个作业再从HDFS重新读取数据进行处理。很明显更高效的方式是，第一个作业直接将数据传递给下游作业。
- MR 默认了map和reduce阶段，map会对中间结果进行分区、排序，reduce会进行合并排序，这一过程并不适用于所有场景。
- 引擎级别的Runtime优化：MR执行计划在编译时已经确定，无法动态调整。然而在执行ETL和Ad-hoc等任务时，根据实际处理的表大小，动态调整join策略、任务并行度将大大缩短任务执行时间。
### 4. 引入DAG
[参考文档](https://hortonworks.com/blog/expressing-data-processing-in-apache-tez/)
- Vertex：定义了用户逻辑（如：map/reduce）与相关的资源与环境
- Edge：定义了上下游Vertex之间的连接方式。
- Scheduling：定义了何时启动consumer Task
- Data source：定义了任务outp的生命周期与可靠性。

__其中edge属性：__
- One-To-One: 第i个producer产生的数据，发送给第i个consumer。这种上下游关系属于Spark的窄依赖。
- Broadcast: producer产生的数据路由都下游所有consumer。这种上下游关系也属于Spark的窄依赖。
- Scatter-Gather: producer将产生的数据分块，将第i块数据发送到第i个consumer。这种上下游关系属于Spark的宽依赖。

__其中scheduling属性：__
- Sequential: Consumer task 需要producer task结束后启动，如：MR。
- Concurrent: Consumer task 与producer task一起启动，如：流计算。

__datasource属性:__
- Persisted: 当任务退出后，该任务output依然存在，但经过一段时间后，可能会被删除，如：Mapper输出的中间结果。
- Persisted-Reliable: 任务output总是存在，比如，MR中reducer的输出结 果，存在HDFS上。
- Ephemeral: 任务输出只有当该task在运行的时候，才存在，如：流计算的    中间结果。

__eg1.0:__
![图片描述](/assets/media/tez原理及优化建议/tapd_48728548_base64_1600345812_64.png)


#### 5. Runtime API——Input/Processor/Output 

Task是Tez的最小执行单元，Vertex中task的数量与该vertex的并行度一致。
__runtime时的优化:__
任务运行时，程序知晓更多任务相关的信息，通过这些信息，我们可以动态修改修改执行计划，比如：修改mapper或reducer数量，决定何时启动reducer等。在Tez中，不同组件通过不同事件类型，进行通信。

- 动态修改reducer并行度：MapTask通过VertexManager类型的事件向ShuffleVertextManager发送信息，比如:所处理的partition大小等。ShuffleVertexManager通过所获得的信息，可以估算出所有Task的输出数据大小，最后来调整下游reduce Vertex的并行度
- reducer"慢"启动(预先启动)：上游MapTask通过事件不断向ShuffleVertexManager汇报任务完成情况，ShuffleVertexManager通过这些信息，可以判断何时启动下游reduceTask与需要启动的reduceTask数量。

___tez session优化:___

- Tez Session: 与数据库session相似，在同一个Tez Session中，可串行执行多个Tez Dag。Tez Session避免了AM的多次启动与销毁，在有多个DAG图的Tez作业（HQL任务）中大大减小了任务执行时间。
- Container复用: 被先后调度到同一个container的多个task所需要的资源，必须与container的资源相互兼容。也就是说，container拥有的资源，如：jar包，Memory，CPU等，需要是task所需资源的“超集”。   
进行container复用时，Tez对Task进行调度。Tez会依据：任务本地性、任务所需资源、pending任务的优先级等因素，进行任务调度。

__相关参数:__
![图片描述](/assets/media/tez原理及优化建议/tapd_48728548_base64_1600346372_96.png)

### 6. 其它参考
1. Tez Configuration
 /https://tez.apache.org/releases/0.9.0/tez-api-javadocs/configs/TezConfiguration.html/ 
2. Hive on Tez 配置参数
 /https://cwiki.apache.org/confluence/display/Hive/Configuration Properties#ConfigurationProperties-Tez/ 
___参考链接：___
- https://hortonworks.com/blog/apache-tez-a-new-chapter-in-hadoop-data-processing/
- http://web.eecs.umich.edu/~mosharaf/Readings/Tez.pdf